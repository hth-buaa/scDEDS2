#' @title Select Training Sets in Dataset
#'
#' @description
#' Selects high-confidence regulatory interactions from iGRN to construct training datasets for predictive modeling.
#' The function applies multiple filtering criteria based on regulatory strength (theta) and integrates cell group state features (TFE, TGA, TGE) for each selected TF–TG pair.
#'
#' @param interest_cell_type_branch_iGRN The output of function get_branch_iGRN.
#' @param top_n_for_max_theta_in_each_regulon Positive integer. Number of top theta values to keep for each TF and each TG independently. Default is 1.
#' @param max_theta_retention_rate_in_tops Numeric between 0 and 1. Quantile threshold applied to thetas within the initial training set. Default is 1 (100%).
#' @param max_theta_retention_rate_in_all Numeric between 0 and 1. Quantile threshold applied to thetas from all possible interactions. Default is 1 (100%).
#' @param retention_number_of_tops Positive integer. Number of top theta interactions to retain. Default is 1000.
#' @param refine Logical. If TRUE, further refines the training set by requiring mutual top membership (TF in top regulons of TG, and TG in top regulons of TF) and retains a top ratio. Default is TRUE.
#' @param keep_all_TF Logical. When \code{refine = TRUE}, if TRUE, ensure that each TF is included in the training set.
#' @param top_ratio_in_refine Numeric between 0 and 1. When \code{refine = TRUE}, retains the top proportion of thetas. Default is 1 (100%).
#' @param interest_cell_type_group The output of function cell_grouping.
#' @param ncores See in ?get_interest_cell_type_data.
#'
#' @returns
#' A nested list structure organized by cell type and branch, containing:
#' \itemize{
#' \item For each branch: A data frame with training datasets including:
#' \itemize{
#' \item \code{TG}: Target gene identifier
#' \item \code{TF}: Transcription factor identifier
#' \item \code{theta_i}: Regulatory strength from iGRN
#' \item \code{TFE_K}, \code{TGA_K}, \code{TGE_K}: Cell group state features for each time point
#' }\item An "all" element containing the combined training dataset across all branches
#' }
#'
#' @details
#' The function performs the following key operations:
#' \enumerate{
#' \item Generates all possible TF–TG pairs from the iGRN and attaches the regulatory strength (theta_i).
#' \item For each TF and each TG, independently selects the top \code{top_n_for_max_theta_in_each_regulon} interactions (by theta_i) to form an initial training set.
#' \item Applies three threshold filters to the initial training set: (a) a quantile threshold on the thetas within the training set (\code{max_theta_retention_rate_in_tops}), (b) a quantile threshold on the thetas from all interactions (\code{max_theta_retention_rate_in_all}), and (c) an absolute number threshold (\code{retention_number_of_tops}). The final training set must satisfy all three.
#' \item If \code{refine} is TRUE and \code{keep_all_TF} is FALSE, further refines the training set by keeping only those interactions where the TF appears in the top regulons of the TG and the TG appears in the top regulons of the TF, and then retains the top \code{top_ratio_in_refine} of thetas.
#' \item If \code{refine} is TRUE and \code{keep_all_TF} is TRUE, retrieve the training set with missing TF on the refined results (theta_i maximum) to ensure that each TF is included in the training set.
#' \item For each branch, attaches the corresponding cell group state features (TFE, TGA, TGE) for each time point to the selected interactions.
#' \item Returns a list for each cell type, with each element corresponding to a branch (and an "all" element) containing the training set data frame.
#' }
#'
#' @section Sampling Strategy:
#' The function uses a stratified sampling approach to ensure that both the top regulators for each gene and the top targets for each TF are represented. The initial training set is formed by taking the top n interactions for each TF and each TG. Then, multiple thresholds are applied to further filter for high-confidence interactions.
#'
#' @note
#' Important considerations:
#' \itemize{
#' \item The function uses parallel processing (via \code{parallel::mclapply}) to speed up computation across cell types. Adjust \code{ncores} according to your system.
#' \item The training set selection is based on the regulatory strength (theta_i) from the iGRN. Ensure that the iGRN and cell group state features are properly generated by the upstream functions.
#' \item The refinement step (\code{refine=TRUE}) can significantly reduce the number of interactions, which may be beneficial for model training but may also remove some potentially important interactions. Adjust the parameters accordingly.
#' }
#'
#' @export
#'
#' @examples
#' \dontrun{
#' interest_cell_type_branch_iGRN = base::readRDS("./3 get iGRN/interest_cell_type_branch_iGRN.rds")
#' interest_cell_type_group = base::readRDS("./2.2 Data Processing - Cell Grouping/interest_cell_type_group.rds")
#' top_n_for_max_theta_in_each_regulon = 1
#' max_theta_retention_rate_in_tops = 0.8
#' max_theta_retention_rate_in_all = 0.8
#' retention_number_of_tops = 1000
#' refine = TRUE
#' keep_all_TF = TRUE
#' top_ratio_in_refine = 0.8
#' ncores = parallel::detectCores() - 1 # in Linux
#' # ncores = 1 # in Windows
#' interest_cell_type_branch_training_set = select_training_set(
#'   interest_cell_type_branch_iGRN = interest_cell_type_branch_iGRN,
#'   interest_cell_type_group = interest_cell_type_group,
#'   top_n_for_max_theta_in_each_regulon = top_n_for_max_theta_in_each_regulon,
#'   max_theta_retention_rate_in_tops = max_theta_retention_rate_in_tops,
#'   max_theta_retention_rate_in_all = max_theta_retention_rate_in_all,
#'   retention_number_of_tops = retention_number_of_tops,
#'   refine = refine,
#'   keep_all_TF = keep_all_TF,
#'   top_ratio_in_refine = top_ratio_in_refine,
#'   ncores = ncores
#' )
#' }
select_training_set = function (interest_cell_type_branch_iGRN = interest_cell_type_branch_iGRN,
                                interest_cell_type_group = interest_cell_type_group,
                                top_n_for_max_theta_in_each_regulon = 1,
                                max_theta_retention_rate_in_tops = 1,
                                max_theta_retention_rate_in_all = 1,
                                retention_number_of_tops = 1000,
                                refine = TRUE,
                                keep_all_TF = TRUE,
                                top_ratio_in_refine = 1,
                                ncores = 1)
{
  t_start = base::Sys.time()
  message("Run: Partitioning Training Sets ", t_start, ".")
  original_dir = base::getwd()
  new_folder = "4.1 Build Prediction Model - Select Training Set"
  if (!base::dir.exists(new_folder)) {
    base::dir.create(new_folder, recursive = TRUE)
    message("Folder already creates: ", new_folder, ".")
  } else {
    message("Folder already exists: ", new_folder, ".")
  }
  base::setwd(new_folder)
  message("The current working directory has been switched to: ", base::getwd(), ".")

  select_training_set_process = function(branch_GRN,
                                         top_n_for_max_theta_in_each_regulon = 1,
                                         max_theta_retention_rate_in_tops = 1,
                                         max_theta_retention_rate_in_all = 1,
                                         retention_number_of_tops = 1000,
                                         refine = TRUE,
                                         keep_all_TF = TRUE,
                                         top_ratio_in_refine = 1,
                                         TFE_T,
                                         TGA_T,
                                         TGE_T) {
    message("Generating all row-column (TG-TF) combinations, and adding regulatory strength theta for each TG_TF pair.")
    n_branch = base::length(branch_GRN)
    all_combinations = base::list()
    for (n in 1:n_branch) {
      all_combinations[[base::paste0("branch_", n, "_GRN")]] = base::expand.grid(
        TG = base::rownames(branch_GRN[[n]]), TF = base::colnames(branch_GRN[[n]]), stringsAsFactors = FALSE
      )
      all_combinations[[base::paste0("branch_", n, "_GRN")]]$theta_i = base::apply(
        all_combinations[[base::paste0("branch_", n, "_GRN")]], 1, function(x) branch_GRN[[n]][x[1], x[2]]
      )
    }
    all_combinations[["GRN"]] = base::do.call(rbind, all_combinations)
    all_combinations[["GRN"]] = all_combinations[["GRN"]][!base::duplicated(all_combinations[["GRN"]]), ]
    stratified_slice = function(data,
                                top_n_for_max_theta_in_each_regulon = 1,
                                max_theta_retention_rate_in_tops = 1,
                                max_theta_retention_rate_in_all = 1,
                                retention_number_of_tops = 1000,
                                refine = TRUE,
                                keep_all_TF = TRUE,
                                top_ratio_in_refine = 1) {
      message("Threshold pretreatment.")
      top_n_for_max_theta_in_each_regulon = base::ifelse(
        top_n_for_max_theta_in_each_regulon < 1.5,
        1,
        base::round(top_n_for_max_theta_in_each_regulon)
      )
      max_theta_retention_rate_in_tops = base::pmin(
        base::pmax(max_theta_retention_rate_in_tops, 0), 1
      )
      max_theta_retention_rate_in_all = base::pmin(
        base::pmax(max_theta_retention_rate_in_all, 0), 1
      )

      message("Ideas for selecting training sets: select the top ", top_n_for_max_theta_in_each_regulon,
              " thetas with the largest values for each gene as the training set, retaining (take the intersection) the top ", max_theta_retention_rate_in_tops * 100,
              "% of the training set, the top ", retention_number_of_tops,
              " entries in the training set, and the top ", max_theta_retention_rate_in_all * 100,
              "% portion from all samples.")

      message("Select the top ", top_n_for_max_theta_in_each_regulon, " thetas with the largest values for each TF.")
      TFregulon_top_n = base::list()
      for (TF in unique(data$TF)) {
        TFregulon = data[data$TF == TF, ]
        TFregulon_top_n[[TF]] = dplyr::slice_max(.data = TFregulon, order_by = theta_i, n = top_n_for_max_theta_in_each_regulon, with_ties = FALSE)
      }
      TFregulon_top_n = data.table::rbindlist(TFregulon_top_n)

      message("Select the top ", top_n_for_max_theta_in_each_regulon, " thetas with the largest values for each TG.")
      TGregulon_top_n = base::list()
      for (TG in unique(data$TG)) {
        TGregulon = data[data$TG == TG, ]
        TGregulon_top_n[[TG]] = dplyr::slice_max(
          .data = TGregulon,
          order_by = theta_i,
          n = top_n_for_max_theta_in_each_regulon,
          with_ties = FALSE
        )
      }
      TGregulon_top_n = data.table::rbindlist(TGregulon_top_n)

      message("Initialize training set.")
      train_set = base::unique(base::rbind(TFregulon_top_n, TGregulon_top_n))

      message("Filter training set based on threshold.")
      train_set$max_theta_retention_rate_in_tops = base::ifelse(
        train_set$theta_i >= stats::quantile(
          train_set$theta_i,
          probs = 1 - max_theta_retention_rate_in_tops,
          na.rm = TRUE
        ), TRUE, FALSE
      )
      train_set$max_theta_retention_rate_in_all = base::ifelse(
        train_set$theta_i >= stats::quantile(
          data$theta_i,
          probs = 1 - max_theta_retention_rate_in_all,
          na.rm = TRUE
        ), TRUE, FALSE
      )
      train_set = dplyr::mutate(
        train_set,
        retention_number_of_tops = dplyr::row_number(dplyr::desc(theta_i)) <= retention_number_of_tops
      )
      message("There are ", base::nrow(train_set), " regulons in training set.")
      message("There are ", base::length(base::unique(train_set$TF)), " TFs in training set.")
      message("TFs are ")
      base::print(base::sort(base::unique(train_set$TF)))
      message("There are ", base::length(base::unique(train_set$TG)), " TGs in training set.")

      if (refine == TRUE) {
        message("Refine training set further.")
        train_set0 = train_set
        train_set = train_set[
          (train_set$TF %in% base::unique(TGregulon_top_n$TF)) &
            (train_set$TG %in% base::unique(TFregulon_top_n$TG)),
        ]
        message("Retain the top ", top_ratio_in_refine * 100, "%.")
        train_set = train_set[train_set$theta_i >= quantile(
          train_set$theta_i, probs = 1 - top_ratio_in_refine , na.rm = TRUE
        ), ]

        message("There are ", base::nrow(train_set), " regulons in training set after refining.")
        message("There are ", base::length(base::unique(train_set$TF)), " TFs in training set after refining.")
        message("TFs are:")
        base::print(base::sort(base::unique(train_set$TF)))
        message("There are ", base::length(base::unique(train_set$TG)), " TGs in training set after refining.")

        if (keep_all_TF == TRUE) {
          TFs_filter = base::setdiff(base::unique(train_set0$TF), base::unique(train_set$TF))

          message("There are ", base::length(TFs_filter), " regulons that are needed to add.")
          message("Added TFs are: ")
          base::print(base::sort(TFs_filter))
          message("Whether add: ", base::length(TFs_filter) > 0)

          if (base::length(TFs_filter) > 0) {
            for (TF_filter in TFs_filter) {
              message("Added TF ", TF_filter, ".")
              TF_filter_train_set = train_set0[train_set0$TF == TF_filter, , drop = FALSE]
              TF_filter_train_set = TF_filter_train_set[base::which.max(TF_filter_train_set$theta_i), , drop = FALSE]
              message("Added sanple: ")
              base::print(TF_filter_train_set)
              train_set = base::rbind(train_set, TF_filter_train_set)
            }

            message("There are ", base::nrow(train_set), " regulons in training set after refining.")
            message("There are ", base::length(base::unique(train_set$TF)), " TFs in training set after refining.")
            message("TFs are:")
            base::print(base::sort(base::unique(train_set$TF)))
            message("There are ", base::length(base::unique(train_set$TG)), " TGs in training set after refining.")
          }
        }
      }

      message("Output training set.")
      train_set = train_set[rowSums(train_set[, c(
        "max_theta_retention_rate_in_tops",
        "max_theta_retention_rate_in_all",
        "retention_number_of_tops")]) == 3, ]
      train_set = base::as.data.frame(train_set[, c("TF", "TG", "theta_i")])
      message("The training set is:")
      base::print(train_set)
      train_set = train_set[!base::duplicated(train_set), ]
      rownames(train_set) = base::paste0(train_set$TF, "_to_", train_set$TG)
      message("After adding rownames, the training set is:")
      base::print(train_set)
      return(train_set)
    }
    slices_GRN = stratified_slice(
      data = all_combinations[["GRN"]],
      top_n_for_max_theta_in_each_regulon = top_n_for_max_theta_in_each_regulon,
      max_theta_retention_rate_in_tops = max_theta_retention_rate_in_tops,
      max_theta_retention_rate_in_all = max_theta_retention_rate_in_all,
      retention_number_of_tops = retention_number_of_tops,
      refine = refine,
      keep_all_TF = keep_all_TF,
      top_ratio_in_refine = top_ratio_in_refine
    )

    message("Adding cell group states (TFE, TGA, TGE).")
    slices_branch_GRN = base::list()
    for (n in 1:n_branch) {
      slices_branch_GRN[[base::paste0("branch", n)]] = slices_GRN
      for (TG_TF in base::rownames(slices_branch_GRN[[base::paste0("branch", n)]])) {
        TF = base::strsplit(TG_TF, "_to_")[[1]][1]
        TG = base::strsplit(TG_TF, "_to_")[[1]][2]
        if (TF %in% base::colnames(branch_GRN[[n]]) && TG %in% base::rownames(branch_GRN[[n]])) {
          for (K in 1:ncol(TFE_T[[n]])) {
            slices_branch_GRN[[base::paste0("branch", n)]][TG_TF, base::paste0("TFE_", K)] = TFE_T[[n]][TF, K]
            slices_branch_GRN[[base::paste0("branch", n)]][TG_TF, base::paste0("TGA_", K)] = TGA_T[[n]][TG, K]
            slices_branch_GRN[[base::paste0("branch", n)]][TG_TF, base::paste0("TGE_", K)] = TGE_T[[n]][TG, K]
          }
        } else {
          slices_branch_GRN[[base::paste0("branch", n)]] = slices_branch_GRN[[base::paste0("branch", n)]][
            !rownames(slices_branch_GRN[[base::paste0("branch", n)]]) %in% TG_TF,
          ]
        }
      }
    }
    slices_branch_GRN[["all"]] = slices_GRN
    return(slices_branch_GRN)
  }
  interest_cell_type_branch_training_set = parallel::mclapply(
    X = base::names(interest_cell_type_branch_iGRN),
    FUN = function(cell_type) {
      message("Partitioning Training Sets from the data of ", cell_type, ".")
      select_training_set_process(
        branch_GRN = interest_cell_type_branch_iGRN[[cell_type]],
        top_n_for_max_theta_in_each_regulon = top_n_for_max_theta_in_each_regulon,
        max_theta_retention_rate_in_tops = max_theta_retention_rate_in_tops,
        max_theta_retention_rate_in_all = max_theta_retention_rate_in_all,
        retention_number_of_tops = retention_number_of_tops,
        refine = refine,
        keep_all_TF = keep_all_TF,
        top_ratio_in_refine = top_ratio_in_refine,
        TFE_T = interest_cell_type_group[[cell_type]][["Branches_TFE_T"]],
        TGA_T = interest_cell_type_group[[cell_type]][["Branches_TGA_T"]],
        TGE_T = interest_cell_type_group[[cell_type]][["Branches_TGE_T"]]
      )
    },
    mc.cores = ncores
  )

  base::names(interest_cell_type_branch_training_set) = base::names(interest_cell_type_branch_iGRN)
  base::setwd(original_dir)
  message("The current working directory has been switched to: ", base::getwd(), ".")
  t_end = base::Sys.time()
  message("Finish: Partitioning Training Sets ", t_end, ".")
  message("Running time: ")
  base::print(t_end - t_start)
  return(interest_cell_type_branch_training_set)
}
